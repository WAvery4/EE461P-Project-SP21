{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting pneumonia using chest x-rays\n",
    "\n",
    "### To Do List\n",
    "\n",
    "#### Research:\n",
    "* CNNs\n",
    "    * How do they work?\n",
    "    * Idea of transfer learning\n",
    "* Unique CNN implementations: AlexNet, CapsNet, GNN\n",
    "    * What is unique about each of these implementations?\n",
    "    \n",
    "#### Implementation:\n",
    "* Basic CNNs (PyTorch, tensorflow, keras)\n",
    "* Transfer learning example\n",
    "* Unique CNN implementations\n",
    "* Understanding what the CNN found important (https://github.com/albermax/innvestigate)\n",
    "\n",
    "#### Blog:\n",
    "* Choosing a service (Medium, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNNs)\n",
    "\n",
    "CNNs are used for classifaction and computer vision. They are made up of three types of layers: convolutional, pooling, and fully-connected (FC). The first layer is a convolutional layer, and the last layer is the only fully-connected layer. The layers in between may be a mix of convolutional and pooling layers [1]. \n",
    "\n",
    "##### Convolutional Layers [1]\n",
    "Convolutiuonal layers have an input, a filter (AKA kernel or feature detector), and a feature map. The feature detector is typically a 2D array of weights, which is applied to a subsection of the input. The dot product between this subsection and the kernel is then calculated. The filter then shifts by a stride, and performs the dot product operation once more, repeating this process until it has covered the entire input. The resulting array of outputs is called the feature map.\n",
    "\n",
    "Some hyperparameters that can be adjusted in the convolutional layer are number of filters, stride, and zero padding. Number of filters affects the depth of the feature map (e.g. three filters results in a depth three feature map). Stride is the number of pixels the kernel moves after each dot product calculation. Zero padding refers to the amount of padding added to an input (eg. an image) to ensure that the filter fits the image.\n",
    "\n",
    "After each convolution, the CNN applies a ReLU to introduce nonlinearities into the network, ensuring that the model is a universal approximator.\n",
    "\n",
    "##### Pooling Layers [1]\n",
    "Similar to a convolutional layer, except the filter does not use weights. Instead it implements a specific type of pooling: max pooling or average pooling. Max pooling is when the filter selects the pixel of maximum value to send to the output array. Average pooling is when the filter calculates the average value in the receptive field (the values that the filter can see).\n",
    "\n",
    "More information is lost in pooling layers, but they \"reduce complexity, improve efficiency, and limit risk of overfitting\".\n",
    "\n",
    "##### Fully-Connected Layer [1]\n",
    "Usually uses a softmax activation function to make the final classification prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Neural Networks (RNNs) [5]\n",
    "\n",
    "RNNs are neural networks that include residual blocks. In residual blocks, layers feed directly into layers 2-3 layers deeper, while also still feeding into the next layer. These connections to deeper layers are called skip connections or residual connections. \n",
    "\n",
    "Generally the layers a NN solve for the true distribution H(x). However, the layers of a residual block solve for the residual! R(x) = Output - Input = H(x) - x => H(x) = R(x) + x. RNNs can also help with the problem of vanishing gradient by using skip connections to back propoagate larger gradients to earlier layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "Briefly introduced in class was the idea of transfer learning, whereby a previously trained neural network is used in a new problem. The ResNet50 network from PyTorch is a pretrained, RNN with 50 layers. ResNet50 is trained on images, and as such, early layers \"learned\" basic image features such as lines and shapes that can be used in any image classification problem. This saves an enormous amount of time and compute power, since those layers no longer need to be trained for new problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to run with Python 3.6, Tensorflow 1.15, and Keras 2.2.4 for iNNvestigate\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 # https://pypi.org/project/opencv-python/\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 150\n",
    "def get_training_data(data_dir):\n",
    "    data = []\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            if img == '.DS_Store' :\n",
    "                continue\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                data.append([resized_arr, class_num])\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print (os.path.join(path, img))\n",
    "                \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_training_data('./chest_xray/train')\n",
    "test = get_training_data('./chest_xray/test')\n",
    "val = get_training_data('./chest_xray/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA (Exploratory Data Analysis) [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "a1 = fig.add_subplot(1,2,1)\n",
    "plt.imshow(train[0][0], cmap='gray')\n",
    "a1.set_title(labels[train[0][1]])\n",
    "a1.set_xticks([])\n",
    "a1.set_yticks([])\n",
    "\n",
    "a2 = fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(train[-1][0], cmap='gray')\n",
    "a2.set_title(labels[train[-1][1]])\n",
    "a2.set_xticks([])\n",
    "a2.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in train:\n",
    "    if(i[1] == 0):\n",
    "        l.append('Pneumonia')\n",
    "    else:\n",
    "        l.append('Normal')\n",
    "        \n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(x=l)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic CNN Implementation [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "    \n",
    "for feature, label in val:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "    \n",
    "for feature, label in test:\n",
    "    x_test.append(feature)\n",
    "    y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    "x_train = np.array(x_train) / 255\n",
    "x_test = np.array(x_test) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing Data For CNN\n",
    "\n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up StratifiedKFold for cross validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "sfk = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation (Grayscales, Horizontal Flips, Vertical Flips, Random Crops, Color Jitters, Translations, Rotations, ...)\n",
    "# Slightly alter the training data to increase the number of training examples and prevent overfitting\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             samplewise_center=False,\n",
    "                             featurewise_std_normalization=False,\n",
    "                             samplewise_std_normalization=False,\n",
    "                             zca_whitening=False,\n",
    "                             rotation_range=30,\n",
    "                             zoom_range=0.2,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=False)\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://faroit.com/keras-docs/2.1.2/models/about-keras-models/\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), strides=1, padding='same', activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer = sgd , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()\n",
    "model.save_weights('./models/keras-untrained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.3, min_lr=0.000001)\n",
    "\n",
    "for train_index, val_index in sfk.split(x_train, y_train):\n",
    "    # Reset weights\n",
    "    model.load_weights('./models/keras-untrained.h5')\n",
    "    \n",
    "    # Reset learning rate if reduced by callback\n",
    "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer = sgd , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "    \n",
    "    X_train, X_val = x_train[train_index], x_train[val_index]\n",
    "    Y_train, Y_val = y_train[train_index], y_train[val_index]\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32), epochs=10, steps_per_epoch = len(X_train) / 32,\n",
    "                   validation_data=[X_val, Y_val], callbacks=[learning_rate_reduction], shuffle=True)\n",
    "    \n",
    "    model.save(f'./models/keras-cnn-k{k}.h5')\n",
    "    k = k + 1\n",
    "    \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for k in range(1,6):\n",
    "    model = load_model(f'./models/keras-cnn-k{k}.h5')\n",
    "    print(f'----- MODEL {k} -----')\n",
    "    acc = model.evaluate(x_test, y_test)[1]\n",
    "    total += acc\n",
    "    print(\"Accuracy of the model is - \" , acc*100 , \"%\")\n",
    "    print()\n",
    "    \n",
    "print(f'Mean: {total / 5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the best model obtained during cross validation and observe the metrics\n",
    "\n",
    "model = load_model(f'./models/keras-cnn-k{1}.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(x_test)\n",
    "y_pred = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(fpr, tpr, label=f'AUC: {roc_auc_score(y_test, y_prob):.2f}')\n",
    "plt.axis([0,1,0,1])\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend(loc='lower right', prop={'size': 20})\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(matrix)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iNNvestigate [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import innvestigate\n",
    "import innvestigate.applications.imagenet\n",
    "import innvestigate.layers as ilayers\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.keras as kutils\n",
    "import innvestigate.utils.keras.checks as kchecks\n",
    "import innvestigate.utils.keras.graph as kgraph\n",
    "\n",
    "innvestigate.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [x_test[i] for i in range(-3, 3)]\n",
    "labels = ['NORMAL' if y_test[i] else 'PNEUMONIA' for i in range(-3, 3)]\n",
    "predictions = [model.predict(x.reshape(1, 150, 150, 1))[0][0] for x in images]\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20,10))\n",
    "\n",
    "for ax, im, l, p in zip(np.append(axs[0], axs[1]), images, labels, predictions):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.set_title(f'True: {l} // Predicted: {p:.2f} ')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an analyzer\n",
    "gradient_analyzer = innvestigate.create_analyzer('guided_backprop', model)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20,10))\n",
    "\n",
    "for ax, im, l, p in zip(np.append(axs[0], axs[1]), images, labels, predictions):\n",
    "    \n",
    "    # Applying the analyzer\n",
    "    analysis = gradient_analyzer.analyze(im.reshape(1, 150, 150, 1))\n",
    "    \n",
    "    ax.imshow(analysis.squeeze(), cmap='gray')\n",
    "    ax.set_title(f'True: {l} // Predicted: {p:.2f} ')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an analyzer\n",
    "dt_analyzer = innvestigate.create_analyzer('deep_taylor', model)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20,10))\n",
    "\n",
    "for ax, im, l, p in zip(np.append(axs[0], axs[1]), images, labels, predictions):\n",
    "    \n",
    "    # Applying the analyzer\n",
    "    a = dt_analyzer.analyze(im.reshape(1, 150, 150, 1))\n",
    "\n",
    "    # Displaying the gradient\n",
    "    a = a.sum(axis=np.argmax(np.asarray(a.shape) == 3))\n",
    "    a /= np.max(np.abs(a))\n",
    "    # Plot\n",
    "    ax.imshow(a, cmap=\"seismic\", clim=(-0.3, 0.3))\n",
    "    ax.set_title(f'True: {l} // Predicted: {p:.2f} ')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with ResNet [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as tt\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder('./chest_xray/train',\n",
    "                         transform=tt.Compose([tt.Resize(255),\n",
    "                                               tt.CenterCrop(224),\n",
    "                                               tt.RandomHorizontalFlip(),\n",
    "                                               tt.RandomRotation(10),\n",
    "                                               tt.RandomGrayscale(),\n",
    "                                               tt.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "                                               tt.ToTensor()\n",
    "                                              ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = round(len(dataset)*0.7)\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images[0:60], nrow=10).permute(1, 2, 0))\n",
    "        break\n",
    "        \n",
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds==labels).item() / len(preds)), preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Model [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaModelBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch, weight):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels, weight=weight)\n",
    "        acc, preds = accuracy(out, labels)\n",
    "        \n",
    "        return {'train_loss': loss, 'train_acc': acc}\n",
    "    \n",
    "    def train_epoch_end(self, outputs):\n",
    "        batch_losses = [x['train_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['train_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        \n",
    "        return {'train_loss': epoch_loss.item(), 'train_acc': epoch_acc.item()}\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images,labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc,preds = accuracy(out, labels)\n",
    "        \n",
    "        return {'val_loss': loss.detach(), 'val_acc':acc.detach(), \n",
    "                'preds':preds.detach(), 'labels':labels.detach()}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()     \n",
    "        \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, train_result, val_result):\n",
    "        print('Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}'.\n",
    "              format(epoch+1, train_result['train_loss'], train_result['train_acc'],\n",
    "                     val_result['val_loss'], val_result['val_acc']))\n",
    "        \n",
    "    def test_prediction(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()] \n",
    "        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]  \n",
    "        \n",
    "        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(),\n",
    "                'test_preds': batch_preds, 'test_labels': batch_labels}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaResnet(PneumoniaModelBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.resnet50(pretrained=True)\n",
    "        for param in self.network.fc.parameters():\n",
    "            param.require_grad = False\n",
    "        num_features = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_features, 2)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def fit(epochs, lr, model, train_loader, val_loader, weight, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = {}\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    best_loss = 1\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_outputs = []\n",
    "        lrs = []\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            outputs = model.training_step(batch, weight)\n",
    "            loss = outputs['train_loss']\n",
    "            train_outputs.append(outputs)\n",
    "            \n",
    "            train_results = model.train_epoch_end(train_outputs)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        val_results = evaluate(model, val_loader)\n",
    "        if val_results['val_loss'] < best_loss and epoch + 1 > 15:\n",
    "            best_loss = min(best_loss, val_results['val_loss'])\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        model.epoch_end(epoch, train_results, val_results)\n",
    "        \n",
    "        to_add = {'train_loss': train_results['train_loss'],\n",
    "                  'train_acc': train_results['train_acc'],\n",
    "                 'val_loss': val_results['val_loss'],\n",
    "                  'val_acc': val_results['val_acc'], 'lrs':lrs}\n",
    "        \n",
    "        for key,val in to_add.items():\n",
    "            if key in history:\n",
    "                history[key].append(val)\n",
    "            else:\n",
    "                history[key] = [val]\n",
    "                \n",
    "        model.load_state_dict(best_model_wts)\n",
    "        \n",
    "        return history, optimizer, best_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "\n",
    "model = to_device(PneumoniaResnet(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "lr = 0.0001\n",
    "grad_clip = None\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam\n",
    "weight = torch.FloatTensor([3876/1342+3876, 1342/(1342+3876)]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to run this on Kaggle since my GPU did not have enough memory\n",
    "\n",
    "# history, optimizer, best_loss = fit(epochs, lr, model, train_dl, val_dl, weight,\n",
    "#                                     grad_clip=grad_clip,\n",
    "#                                     weight_decay=weight_decay,\n",
    "#                                     opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_checkpoint('./models/PneumoniaResnet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_predict(model, test_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader] \n",
    "    results = model.test_prediction(outputs)                          \n",
    "    print('test_loss: {:.4f}, test_acc: {:.4f}'\n",
    "          .format(results['test_loss'], results['test_acc']))\n",
    "    \n",
    "    return results['test_preds'], results['test_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder('./chest_xray/test', \n",
    "                           transform=tt.Compose([tt.Resize(255),\n",
    "                                                 tt.CenterCrop(224),                                                              \n",
    "                                                 tt.ToTensor()\n",
    "                                                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_dataset, batch_size=256)\n",
    "# test_dl = DeviceDataLoader(test_dl, device)\n",
    "preds,labels = test_predict(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, figsize=(12,8), cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.xlabel('Predicted Label', fontsize=18)\n",
    "plt.ylabel('True Label', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with FastAI [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.data.all import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './chest_xray/train'\n",
    "fnames = get_image_files(path)\n",
    "\n",
    "def label_func(x): return x.parent.name\n",
    "\n",
    "dls = ImageDataLoaders.from_path_func(path, fnames, label_func, item_tfms=Resize(224), bs=16, num_workers=0,\n",
    "                                      batch_tfms=aug_transforms(pad_mode='zeros', max_warp=0, max_zoom=1)) \n",
    "dls.show_batch(max_n=9, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, pretrained=True)\n",
    "\n",
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CapsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is starting point I attempted, for text data not images\n",
    "https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-capsule-networks\n",
    "\n",
    "#Another starting point attempt\n",
    "https://www.analyticsvidhya.com/blog/2018/04/essentials-of-deep-learning-getting-to-know-capsulenets/\n",
    "    \n",
    "#Here is a good library I fiddled with, should be possible to use with our dataset\n",
    "https://github.com/naturomics/CapsLayer\n",
    "    \n",
    "#My next step was going to be this video + the code in description\n",
    "https://www.youtube.com/watch?v=2Kawrd5szHE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying from .. https://www.kaggle.com/rodcardoso92/using-vgg-capsnet-to-diagnose-pneumonia/comments\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras import backend as K\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "IMG_SIZE = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataGenerator(train_batch, val_batch, IMG_SIZE):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                 rescale=1./255,\n",
    "                                 rotation_range=10,\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True)\n",
    "\n",
    "    datagen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)\n",
    "\n",
    "    train_gen = datagen.flow_from_directory('./chest_xray/train/',\n",
    "                                            target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                            color_mode='rgb', \n",
    "                                            class_mode='categorical',\n",
    "                                            batch_size=train_batch)\n",
    "\n",
    "    val_gen = datagen.flow_from_directory('./chest_xray/val/', \n",
    "                                          target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                          color_mode='rgb', \n",
    "                                          class_mode='categorical',\n",
    "                                          batch_size=val_batch)\n",
    "\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                 rescale=1./255)\n",
    "    \n",
    "    datagen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)\n",
    "\n",
    "    test_gen = datagen.flow_from_directory('./chest_xray/test/', \n",
    "                                           target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                           color_mode='rgb', \n",
    "                                           class_mode='categorical',\n",
    "                                           shuffle=False)\n",
    "    \n",
    "    return train_gen, val_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
    "    return scale * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=-1):\n",
    "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "    return ex / K.sum(ex, axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    lamb, margin = 0.5, 0.1 #default lambda 0.5 - but test with lambda with 0.9 - 0.1\n",
    "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
    "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capsule(Layer):\n",
    "    \"\"\"A Capsule Implement with Pure Keras\n",
    "    There are two vesions of Capsule.\n",
    "    One is like dense layer (for the fixed-shape input),\n",
    "    and the other is like timedistributed dense (for various length input).\n",
    "\n",
    "    The input shape of Capsule must be (batch_size,\n",
    "                                        input_num_capsule,\n",
    "                                        input_dim_capsule\n",
    "                                       )\n",
    "    and the output shape is (batch_size,\n",
    "                             num_capsule,\n",
    "                             dim_capsule\n",
    "                            )\n",
    "\n",
    "    Capsule Implement is from https://github.com/bojone/Capsule/\n",
    "    Capsule Paper: https://arxiv.org/abs/1710.09829\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_capsule,\n",
    "                 dim_capsule,\n",
    "                 routings=3, # Test number of routing with (1, 2, 3, 4) - Default = 3\n",
    "                 share_weights=True,\n",
    "                 activation='squash',\n",
    "                 **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'squash':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(1, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.kernel = self.add_weight(\n",
    "                name='capsule_kernel',\n",
    "                shape=(input_num_capsule, input_dim_capsule,\n",
    "                       self.num_capsule * self.dim_capsule),\n",
    "                initializer='glorot_uniform',\n",
    "                trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
    "        but replace b = b + <u,v> with b = <u,v>.\n",
    "\n",
    "        This change can improve the feature representation of Capsule.\n",
    "\n",
    "        However, you can replace\n",
    "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
    "        with\n",
    "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
    "        to realize a standard routing.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.share_weights:\n",
    "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
    "        else:\n",
    "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(inputs)[0]\n",
    "        input_num_capsule = K.shape(inputs)[1]\n",
    "        hat_inputs = K.reshape(hat_inputs,\n",
    "                               (batch_size, input_num_capsule,\n",
    "                                self.num_capsule, self.dim_capsule))\n",
    "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
    "\n",
    "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
    "        for i in range(self.routings):\n",
    "            c = softmax(b, 1)\n",
    "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
    "                if K.backend() == 'theano':\n",
    "                    o = K.sum(o, axis=1)\n",
    "\n",
    "        return o\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = 32\n",
    "val_batch = 1\n",
    "\n",
    "train, val, test = DataGenerator(train_batch, val_batch, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "\n",
    "# A InceptionResNetV2 Conv2D model\n",
    "model = VGG16(include_top=False, weights='imagenet', input_tensor=input_image)\n",
    "output = Conv2D(256, kernel_size=(9, 9), strides=(1, 1), activation='relu')(model.output)\n",
    "x = Reshape((-1, 256))(output)\n",
    "capsule = Capsule(2, 16, 4, True)(x)\n",
    "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
    "model = Model(inputs=input_image, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"weights.h5\", \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='min')\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min', restore_best_weights=True)\n",
    "\n",
    "callback_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    if i < 15:\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "\n",
    "model.compile(loss=margin_loss, optimizer=SGD(lr=lr, momentum=0.9), metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val, \n",
    "                    validation_steps = len(val.classes)//val_batch,\n",
    "                    steps_per_epoch=len(train.classes)//train_batch,\n",
    "                    callbacks=callback_list)\n",
    "    \n",
    "loss, acc = model.evaluate_generator(test, len(test))\n",
    "\n",
    "print (\"\\n\\n================================\\n\\n\")\n",
    "print (\"Loss: {}\".format(loss))\n",
    "print (\"Accuracy: {0:.2f} %\".format(acc * 100))\n",
    "print (\"\\n\\n================================\\n\\n\")\n",
    "\n",
    "test.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO (Ethan planning to work on this sunday morning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] https://www.ibm.com/cloud/learn/convolutional-neural-networks\n",
    "\n",
    "[2] https://www.kaggle.com/madz2000/pneumonia-detection-using-cnn-92-6-accuracy\n",
    "\n",
    "[3] https://data.mendeley.com/datasets/rscbjbr9sj/2 (THIS IS THE DATASET)\n",
    "\n",
    "[4] https://www.kaggle.com/teyang/pneumonia-detection-resnets-pytorch\n",
    "\n",
    "[5] https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec\n",
    "\n",
    "[6] https://course19.fast.ai/videos/?lesson=1\n",
    "\n",
    "[7] Alber, M., Lapuschkin, S., Seegerer, P., Hägele, M., Schütt, K. T., Montavon, G., Samek, W., Müller, K. R., Dähne, S., & Kindermans, P. J. (2019). iNNvestigate neural networks! Journal of Machine Learning Research, 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspenv",
   "language": "python",
   "name": "dspenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
